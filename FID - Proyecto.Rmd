---
title: "FID - Predicción del Mundial 2022"
author: "Equipo8"
output: html_notebook
---

## Introducción al proyecto

En este proyecto queremos abordar la predicción de partidos del mundial de fútbol de Qatar 2022. Para ello, emplearemos distintas técnicas que hemos visto en clase para realizar esta predicción.

Usaremos el siguiente dataset de Kaggle, <https://www.kaggle.com/datasets/brenda89/fifa-world-cup-2022>, donde podemos encontrar los resultados exactos de partidos de futbol de selecciones desde 1993 hasta 2022. El proyecto constará de los dos siguientes algoritmos:

1.  Aprendizaje supervisado: predicción del resultado de partidos del mundial de Qatar 2022.

2.  Aprendizaje no supervisado: Agrupación de equipos en base a sus puntuaciones de defensa, centro y ataque.

Primero, empezaremos instalando y cargando todas las librerías que necesitaremos para el proyecto, y leyendo el dataset que hemos mencionado anteriormente.

**Carga de librerías y lectura del dataset**

```{r}
library(caret)
library(tidyverse)
library(readr)
library(randomForest)
library(dplyr)
library(DescTools)
library(corrplot)
library(ggplot2)
library(ggrepel)
```

**Análisis explotatorio de los datos**

```{r}
international_matches <- read_csv("datasets/international_matches.csv")
international_matches
```

En nuestro dataset tenemos 25 columnas con 23921 filas, con información sobre partidos desde 1993 a 2022. Estos partidos contienen los equipos que lo jugaron, dónde lo jugaron, cuándo lo jugaron, qué resultado obtuvieron, el torneo del partido y información relativa sobre el rendimiento en portería, defensa, mediocentro y ataque de ambos equipos.

## Aprendizaje Supervisado: Predicción de resultados

Primero debemos decidir si para nuestro algoritmo predictor necesitaremos todas las variables o podemos deshacernos de algunas para agilizar la computación.

**Selección de los datos**

Como se puede ver en la tabla, el dataset contiene datos de partidos desde 1993. No obstante, de cara a entrenar un modelo que realice predicciones sobre partidos recientes sólo nos serían útiles los partidos de la última década, ya que por ejemplo, los partidos de Uruguay de 1993 no tendrán efecto en los del 2022 ya que son equipos totalmente distintos. Así, vamos a estudiar los partidos hasta 2012, fecha de debut de muchos de los jugadores que se retirarán después de este mundial.

```{r}
supervised_international_matches <- international_matches[as.Date(international_matches$date) >= as.Date("2012-01-01"), ]

supervised_international_matches
```

**Balanceo de clases**

Comenzaremos estudiando el desbalanceo de clases. Como se puede ver a continuación, se tiene un 48% de ejemplos etiquetados como "Victoria", un 29% "Derrota" y un 23% "Empate", aproximadamente.

```{r}
prop.table(table(supervised_international_matches$home_team_result))
```

Las clases se encuentran desbalanceadas, aunque no de una forma muy significativa. Sin embargo, esto será un factor a tener en cuenta a la hora de seleccionar la métrica para evaluar y comparar los distintos modelos.

**Correlación de atributos**

Otro de los puntos a tener en cuenta previamente al entrenamiento del modelo es la correlación entre los atributos del conjunto de datos. Dado que la clase a predecir es una variable categórica (nominal), se ha utilizado el coeficiente V de Crammer para evaluar el grado de asociación entre los atributos. Cabe destacar que se han realizado dos evaluaciones, ya que que podemos distinguir entre dos tipos de partidos:

-   **Amistosos:** En estos partidos existe un equipo local y un equipo visitante, pues se juegan en la ciudad del equipo local. Esto puede provocar que el resultado se vea afectado por factores externos (mayor cantidad de aficionados locales en el campo), al contrario que e. y en torneos oficiales no existe local ni visitante.

```{r}

# Get official and friendly matches
allMatches <- supervised_international_matches[,-c(1,2,3,4,5,6,7,8,9,15,16)][1:6]
officialMatches <- allMatches[allMatches$tournament != "Friendly",]
friendlyMatches <- allMatches[allMatches$tournament == "Friendly", -c(3)]

# Use CramerV as input for corrplot
mOfficial <- DescTools::PairApply(officialMatches, DescTools::CramerV)
mFriendly <- DescTools::PairApply(friendlyMatches, DescTools::CramerV)

# Display only strongly associated:
mOfficial[mOfficial < 0.5] <- 0
mFriendly[mFriendly < 0.5] <- 0

# Calculate correlation:
mOfficialCor <- scales::rescale(mOfficial, to=c(0,1))
mFriendlyCor <- scales::rescale(mFriendly, to=c(0,1))

# Plot
corrplot::corrplot(mOfficialCor, title = "Official matches correlation Plot", method="shade", tl.col="black", tl.srt=35, addCoef.col = 1, col.lim = c(0,1))
corrplot::corrplot(mFriendlyCor, title = "Friendly matches correlation Plot", method="shade", tl.col="black", tl.srt=35, addCoef.col = 1, col.lim = c(0,1))
```

A la vista de los gráficos de correlación, se puede deducir que la ciudad influye en el resultado de manera significativa. Dado que se pretenden predecir los resultados del mundial de 2022, que consta de 65 partidos oficiales, este será un factor determinante a la hora de seleccionar el conjunto de atributos que tomará nuestro modelo como entrada. Eliminaremos los partidos amistosos del dataset para trabajar sólo con partidos oficiales.

Ahora que hemos analizado el dataset, vamos a realizar algunas técnicas de preprocesado para poder mejorar el csv.

**Corrección del balanceo de clases**

Dado que la mayoría de partidos son clasificatorios, no es posible un empate, por lo que de cara al objetivo del problema contemplaremos dos clases: "Victoria" y "No victoria". Siendo esta última la suma de los empates y derrotas del equipo local. De esta manera corregiríamos también el problema del balanceo de clases, obteniendo un 51% de Victorias frente a un 49% de victorias aproximadamente.

```{r}

# Use gsub() to replace all instances of "Draw" and "Lose" for "No Win"
supervised_international_matches$home_team_result <- gsub("Draw", "Lose", supervised_international_matches$home_team_result)

supervised_international_matches$home_team_result <- gsub("Lose", "NoWin", supervised_international_matches$home_team_result)

prop.table(table(supervised_international_matches$home_team_result))
```

**Preselección de atributos**

Para el algoritmo predictivo de aprendizaje supervisado eliminaremos todas las columnas detrás de la 17. Estas columnas nos dan información sobre la puntuación general que obtuvo un equipo en defensa, centro y delantera, y no nos son relevantes ya que ganar por 1 gol es igual que ganar por 10, o hacer 10 paradas en un partido no importa si al final el equipo ha perdido. (Usaremos estos datos más adelante para el algoritmo no supervisado).

```{r}
colnames <- colnames(international_matches)

# Eliminamos las ultimas variables de información de equipo, defensa, centro y ataque
supervised_international_matches <- supervised_international_matches[, colnames[1:17]]

#Eliminamos la fecha de los partidos y la puntuación de los partidos, ya que nuestro algoritmo debe predecir Victoria/Derrota, no el resultado exacto
supervised_international_matches <- supervised_international_matches[, -c(1, 10, 11)]

supervised_international_matches
```

**Evaluación de los atributos - Random Forest**

Ahora, vamos a hacer un análisis de la importancia de las variables restantes del dataset. Usaremos un algoritmo de tipo Random Forest, entrenando primero el dataset con Cross Validation 3-Fold para evitar el Overfitting. Para ello, dividimos el dataset "supervised_international_matches" en 2 partes, un 70% del dataset lo usaremos para entrenar y el otro 30% para validar.

```{r}

# Create training and test set, based on 70/30 distribution.
supervised_partition <- createDataPartition(supervised_international_matches$home_team_result, p = 0.7, list = FALSE)

supervised_training_set <- supervised_international_matches[supervised_partition,]
supervised_test_set <- supervised_international_matches[-supervised_partition,]

```

Una vez creados las particiones, entrenamos el modelo con el método 3-fold CV:

```{r}
set.seed(355)

## 3-fold CV
supervised_fit_control <- trainControl(
                           method = "repeatedcv",
                           number = 3,
                           repeats = 3)

supervised_random_forest <- train(home_team_result ~., data = supervised_training_set,
            method = "rf",
            trControl = supervised_fit_control)

supervised_var_importance <- varImp(supervised_random_forest)
plot(supervised_var_importance, main = "Dataset Variable Importance (Random Forest)")

supervised_var_importance
```

Como podemos ver, no podemos ver. Al tener tantos equipos de fútbol, esta creando una variable por cada equipo y resultado.

**Codificación Label Encode y re-evaluación**

Podemos solucionar esto transformando los equipos a números, mapeandolos con un diccionario. De esta manera, por ejemplo, Senegal pasa a ser 1, Holanda a 2... Transformaremos todas las columnas con valores string o character a int según un diccionario para poder rehacer la transformación. También, tenemos una variable booleana, que explica si el partido fue en una localización neutral (el país donde se juega el partido no es ninguno de los equipos nacionales jugando) que transformaremos a int también (1,0)

```{r}

supervised_training_set_encoded <- supervised_training_set

transform_column_string_to_int <- function(col){
  col <- as.numeric(factor(col))
}

#Transformamos la columna booleana a 0 y 1
supervised_training_set_encoded$neutral_location <- as.integer(as.logical(supervised_training_set_encoded$neutral_location))

# Seleccionar solo las columnas que contienen strings
columns <- names(supervised_training_set_encoded)[sapply(supervised_training_set_encoded, is.character)]

# Evitar hacer label encoding de la variable a predecir para evitar modelos de regresion
columns <- head(columns, -1)

# Aplicar una función a cada columna y guardar el resultado en una lista
result <- lapply(supervised_training_set_encoded[, columns], transform_column_string_to_int)

# Asignar el resultado de vuelta al dataframe
supervised_training_set_encoded[, columns] <- result

supervised_training_set_encoded
```

Ahora vamos a repetir el proceso de Random Forest una vez aplicado Label Encoding al dataset

```{r}

# Repetimos el proceso de Random Forest tras aplicar LabelEncoding
set.seed(355)

## 3-fold CV
supervised_fit_control <- trainControl(
                           method = "repeatedcv",
                           number = 3,
                           repeats = 3)

supervised_random_forest <- train(home_team_result ~., data = supervised_training_set_encoded,
            method = "rf",
            trControl = supervised_fit_control)

supervised_random_forest

supervised_var_importance <- varImp(supervised_random_forest)
plot(supervised_var_importance, main = "Encoded Dataset Variable Importance (Random Forest)")
```

Ahora sí podemos apreciar mejor los resultados del análisis de importancia de las variables. Como esperábamos, las variables que dan información sobre el ranking fifa son las más importantes. El ranking FIFA es el ranking oficial de selecciones, ordenadas de mejor a peor. Tiene sentido que una sección rankeada 1 tenga mayor probabilidad de ganarle a una selección rankeada 100, por eso esperábamos un resultado así.

**Infuencia de la correlación en la selección de atributos**

Sin embargo nos sorprende la importancia de las variables city, country y torneo. Tal y como se estudió al comienzo en el análisis de la correlación, la variable city (que a su vez está correlada con el país y el torneo) influye en el resultado de los partidos cuando estos son amistosos.

Para confirmar los resultados del primer análisis, vamos a estudiar qué relevancia tienen estas variables si solo se tienen en cuenta los partidos amistosos, por lo que repetimos el algoritmo anterior para partidos amistosos:

```{r}
set.seed(355)

supervised_friendly_matches <- supervised_international_matches[supervised_international_matches$tournament == "Friendly",]


supervised_friendly_partition <- createDataPartition(supervised_friendly_matches$home_team_result, p = 0.7, list = FALSE)

supervised_friendly_training_set <- supervised_friendly_matches[supervised_friendly_partition,]
supervised_friendly_test_set <- supervised_friendly_matches[-supervised_friendly_partition,]

supervised_friendly_training_set_encoded <- supervised_friendly_training_set

#Transformamos la columna booleana a 0 y 1
supervised_friendly_training_set_encoded$neutral_location <- as.integer(as.logical(supervised_friendly_training_set_encoded$neutral_location))

# Seleccionar solo las columnas que contienen strings
columns <- names(supervised_friendly_training_set_encoded)[sapply(supervised_friendly_training_set_encoded, is.character)]

# Aplicar una función a cada columna y guardar el resultado en una lista
result <- lapply(supervised_friendly_training_set_encoded[, columns], transform_column_string_to_int)

# Asignar el resultado de vuelta al dataframe
supervised_friendly_training_set_encoded[, columns] <- result

supervised_friendly_partition <- trainControl(## 10-fold CV
                           method = "repeatedcv",
                           number = 3,
                           ## repeated ten times
                           repeats = 3)

supervised_friendly_random_forest <- train(home_team_result ~., data = supervised_friendly_training_set_encoded,
            method = "rf",
            trControl = supervised_friendly_partition)

supervised_friendly_var_importance <- varImp(supervised_friendly_random_forest)
plot(supervised_friendly_var_importance, main = "Friendly Variable Importance (Random Forest)")
```

Podemos ver que ahora, city y away_team tienen casi la misma importancia que el ranking fifa. City ya que los amistosos que se juegan si tienen equipo local y todo el estadio es del mismo equipo. away_team es porque el equipo visitante casi siempre pierde. Sabiendo que en el mundial no existe club local ni visitante, vamos a eliminar estas colunmas y volver a realizar este análisis.

```{r}
set.seed(355)

supervised_international_matches <- supervised_international_matches[supervised_international_matches$tournament != "Friendly",]

supervised_international_matches <- supervised_international_matches[, -c(3, 4, 9, 10, 11, 12, 13)]


supervised_partition <- createDataPartition(supervised_international_matches$home_team_result, p = 0.7, list = FALSE)

supervised_training_set <- supervised_international_matches[supervised_partition,]
supervised_test_set <- supervised_international_matches[-supervised_partition,]

supervised_training_set_encoded <- supervised_training_set

# Seleccionar solo las columnas que contienen strings
columns <- names(supervised_training_set_encoded)[sapply(supervised_training_set_encoded, is.character)]

# Aplicar una función a cada columna y guardar el resultado en una lista
result <- lapply(supervised_training_set_encoded[, columns], transform_column_string_to_int)

# Asignar el resultado de vuelta al dataframe
supervised_training_set_encoded[, columns] <- result

supervised_fit_control <- trainControl(
                           method = "repeatedcv",
                           number = 3,
                           repeats = 3)

supervised_random_forest <- train(home_team_result ~., data = supervised_training_set_encoded,
            method = "rf",
            trControl = supervised_fit_control)

supervised_var_importance <- varImp(supervised_random_forest)
plot(supervised_var_importance, main = "Clean Variable Importance (Random Forest)")
```

**Selección final de atributos**

Podemos ver que ahora sí, las variables que explican el problema son las correspondientes al ranking fifa. Además, la variable shoot_out, que explica si ha habido tanda de penalties no aporta nada de información, no es relevante. Esto significa que los penalties son una lotería, como muchos futbolístas y técnicos afirman. Vamos a mostrar el dataset completo ahora con un summary.

```{r}
summary(supervised_international_matches)

```

**Limpieza del notebook**

Para limpiar el notebook, vamos a eliminar todas las variables del entorno y vamos a cargar los datos preprocesados directamente, del apartado anterior.

```{r}
rm(list = ls())

international_matches <- read_csv("datasets/international_matches.csv")

colnames <- colnames(international_matches)

# Get data from 2012
supervised_international_matches <- international_matches[as.Date(international_matches$date) >= as.Date("2012-01-01"), ]

# Replace "Draw" and "Lose" for "NoWin"
supervised_international_matches$home_team_result <- gsub("Draw", "Lose", supervised_international_matches$home_team_result)

supervised_international_matches$home_team_result <- gsub("Lose", "NoWin", supervised_international_matches$home_team_result)

# Remove unused columns
supervised_international_matches <- supervised_international_matches[, colnames[1:17]]

supervised_international_matches <- supervised_international_matches[, -c(1, 10, 11)]

# Remove friendly matches
supervised_international_matches <- supervised_international_matches[supervised_international_matches$tournament != "Friendly",]

supervised_international_matches <- supervised_international_matches[, -c(3, 4, 9, 10, 11, 12, 13)]

# Create trainning and test set
supervised_partition <- createDataPartition(supervised_international_matches$home_team_result, p = 0.7, list = FALSE)

supervised_training_set <- supervised_international_matches[supervised_partition,]
supervised_test_set <- supervised_international_matches[-supervised_partition,]

supervised_training_set_encoded <- supervised_training_set
supervised_test_set_encoded <- supervised_test_set


# Seleccionar solo las columnas que contienen strings
columns <- names(supervised_training_set_encoded)[sapply(supervised_training_set_encoded, is.character)]

columns <- head(columns, -1)

transform_column_string_to_int <- function(col){
  col <- as.numeric(factor(col))
}

# Aplicar una función a cada columna y guardar el resultado en una lista
supervised_training_set_encoded[, columns] <- lapply(supervised_training_set_encoded[, columns], transform_column_string_to_int)

supervised_test_set_encoded[, columns] <- lapply(supervised_test_set_encoded[, columns], transform_column_string_to_int)
```

**Entrenamiento de múltiples modelos**

Ahora, con el dataset curado, vamos a empezar a aplicar distintos algoritmos de predicción para obtener el que mejor se comporte. Para ello, vamos a aplicar primero NaiveBayes con los datos sin hacer LabelEncoding, y luego probaremos KNN y SVC con LabelEncoding.

```{r}

set.seed(355)

supervised_control <- trainControl(
                method = "repeatedcv",
                number = 3,
                classProbs = TRUE,
                savePredictions = "final",
                summaryFunction = twoClassSummary,
                repeats = 3)

# Usar Naive-Bayes con los datos sin LabelEncoding.

supervised_naive_bayes <- train(home_team_result ~., data = supervised_training_set,
            method = "naive_bayes",
            trControl = supervised_control,
            metric="ROC")

# Luego probar con los datos ya codificados con los métodos de KNN y SVC

supervised_knn <- train(home_team_result ~., data = supervised_training_set_encoded,
            method = "knn",
            trControl = supervised_control,
            metric = "ROC",
            tuneGrid = data.frame(k = seq(11,85,by = 2)))


supervised_svm <- train(home_team_result ~., data = supervised_training_set_encoded,
            method = "svmLinear",
            trControl = supervised_control,
            preProcess = c("center","scale"),
            metric = "ROC",
            tuneGrid = expand.grid(C = seq(0.0001, 5, length = 25)))
```

**Evaluación de modelos**

Vamos a comparar esos modelos que hemos obtenido para seleccionar el mejor y poder empezar a predecir el resultado de los partidos.

```{r}
# Comparación de modelos
resam <- resamples(list(NB  = supervised_naive_bayes,
                        KNN = supervised_knn,
                        SVM = supervised_svm)
                   )
summary(resam)
```

**Selección del mejor clasificador**

Esta es una de las partes cruciales del proyecto. Para determinar qué modelo es el mejor, tendremos que tener en cuenta las métricas de rendimiento más importantes para nuestra aplicación concreta, la predicción de partidos.

No hay un modelo mejor, sino que para cada caso, elegiremos uno guiándonos por las métricas de evaluación. Tenemos las siguientes métricas:

1.  La sensibilidad de un modelo de clasificación es la fracción de instancias positivas que son correctamente identificadas por el modelo. Es decir, la sensibilidad mide cuán bueno es el modelo para detectar las instancias positivas

2.  La especificidad es la fracción de instancias negativas que son correctamente identificadas por un modelo de clasificación. Es decir, mide cuán bueno es el modelo para detectar las instancias negativas.

3.  La AUC (Área bajo la Curva) o AUROC (Área bajo la Curva ROC) es una medida de rendimiento comúnmente utilizada en el análisis de clasificación binaria. La curva ROC es un gráfico que muestra la tasa de verdaderos positivos (sensibilidad) en el eje Y en función de la tasa de falsos positivos (1 - especificidad) en el eje X, para diferentes umbrales de clasificación.

Por ejemplo, si somos corredores de apuestas, nos interesa saber con la mayor exactitud, en qué medida un equipo ganará seguro o perderá seguro, para realizar apuestas seguras, usando la sensibilidad (gana seguro) o especificidad (pierde seguro). Sin embargo, como queremos realizar una predicción imparcial y neutra, vamos a utilizar la AUROC, ya que está basada en las métricas anteriores de manera equitativa.

SVM obtiene las mejores puntuaciones en todos benchmarks de AUROC frente a los demás modelos. Por este motivo, nos quedamos con SVM para realizar la predicción final.

```{r}
# Nos quedamos con el modelo con mejor media de AUROC.
final_model <- supervised_svm
```

**Predicción de los resultados del mundial de Qatar 2022**

Con el mejor modelo ya seleccionado, ahora vamos a realizar la parte final del ejercicio supervisado, la predicción de partidos del mundial. Para ello, cargamos el dataset "results", que contiene los resultados de todos los partidos jugados en el mundial. Algo importante a notar, es que este dataset debe tener la misma estructura que el dataset con el que entrenamos al modelo. Sin embargo, no había ningún dataset con la misma estructura en Internet, por ello hemos montado un script (en python) que nos ha parseado todo el mundial de la manera adecuada para el algoritmo. (/scripts/parser.py)

```{r}
worldcup_2022_matches <- read_csv("datasets/results.csv")
worldcup_2022_matches
```

Como el csv de entrada debe mantener el formato del csv usado para entrenar, también debemos aplicar LabelEncoding a este dataset. Sino, no será capaz de aprender y encontrar las relaciones para predecir.

```{r}
# Funcion de mapeo a label encoding
labelMapper <- function(columna_valores, columna_codificacion) {
  for(valor in columna_valores) {
    indice <- which(columna_valores == valor) 
    if (length(indice) > 0) { 
      columna_valores[indice] <- columna_codificacion[indice]  }
  }
  return (as.numeric(factor(columna_valores)))
}

# Aplicacion de label encoding a las columnas home_team y away_team
worldcup_2022_matches_encoded <- worldcup_2022_matches

worldcup_2022_matches_encoded$home_team <- labelMapper(worldcup_2022_matches$home_team, supervised_training_set_encoded$home_team)

worldcup_2022_matches_encoded$away_team <- labelMapper(worldcup_2022_matches$away_team, supervised_training_set_encoded$away_team)

worldcup_2022_matches_encoded
```

Ahora, vamos a predecir finalmente todos los partidos. Nuestro algoritmo predice las probabilidades de ganar o no ganar del equipo local.

**Fase de grupos**: Si las probabilidades de ganar superan un umbral del 0.65, podemos el algoritmo dirá que el equipo local va a ganar el partido. Si las probabilidades de no ganar son del 0.65, el algoritmo dirá que el equipo local perderá. En caso contrario, si ninguna de las dos probabilidades son lo suficientemente fuertes, el algoritmo dirá que el partido quedará en empate.

**Eliminatorias**: En este caso, no se puede empatar. Si los dos equipos empatan, van a la prórroga, y si empatan en la prórroga irán a penalties. Debe haber un vencedor y un vencido obligatoriamente. Por ello, si las probabilidades de ganar superan un umbral del 0.5, podemos el algoritmo dirá que el equipo local va a ganar el partido. Si las probabilidades de no ganar son del 0.5, el algoritmo dirá que el equipo local perderá.

```{r}

# Division en fase de grupos y clasificatoria
knockout <- worldcup_2022_matches_encoded[str_detect(worldcup_2022_matches_encoded$group, regex("Group [A-H]")),1:7]

classif <- worldcup_2022_matches_encoded[!str_detect(worldcup_2022_matches_encoded$group, regex("Group [A-H]")),1:7]

# Hace predicciones sobre el conjunto de prueba
probsClassif <- predict(final_model,classif, type="prob")
probsKnockout <-predict(final_model,knockout, type="prob")

# Transforma las probabilidades a etiquetas "Win" "Lose" y "Draw" en fase de grupos y "Win" y "Lose" si es un partido clasificatorio
probsClassif <- factor(ifelse(probsClassif$Win > 0.5, "Win", "Lose"))
probsKnockout <- factor(
  ifelse(probsKnockout$Win > 0.65, "Win", 
  ifelse(probsKnockout$NoWin > 0.65, "Lose", "Draw" )))

probs <- c(probsKnockout, probsClassif)

# Crea un nuevo dataset con los resultados para su visualizacion
resultds <- worldcup_2022_matches[, -c(-1,-2,-8)]
resultds$home_team_result_pred <- probs
resultds
```

Finalmente, tenemos la predicción de los partidos. Ahora podemos compararlos con los resultados reales que se han dado, y podemos obtener las métricas de acierto y fallo usando la matriz de confusión

```{r}
true_labels <- as.factor(worldcup_2022_matches$home_team_result)

# Calcula la matriz de confusión
confusion_matrix <- confusionMatrix(probs, true_labels, mode="everything")
confusion_matrix
```

Podemos ver que el ACC es del 45%, lo que significa que nuestro modelo no predice con mucha precisión los resultados. Esto se debe a que en este mundial, se han obtenido resultados realmente extraños, como Arabia Saudí venciendo a la campeona Argentina, Marruecos llegando a las semifinales del mundial (primera vez en toda la historia de fútbol que una selección africana llega a semifinales), España siendo eliminadas en octavos y la favorita Brasil siendo eliminada en cuartos.

El fútbol es muy impredecible en muchos aspectos, pero si nos fijamos en las métricas, nuestro algoritmo es capaz de acertar con un índice de casi el 90% cuando un equipo local va a perder. Podríamos usar este algoritmo para encontrar partidos seguros y apostar con una tasa del 90% de acierto.

## Aprendizaje No Supervisado: Clasificación de equipos según sus métricas

Vamos a diseñar un algoritmo de aprendizaje no supervisado para la segunda parte del proyecto. Nuestra idea es, en base a las columnas de puntuación del dataset original, clusterizar los equipos en base a sus puntuaciones en portería, defensa, mediocentro y ataque y ver qué conclusiones podemos obtener. Usaremos un algoritmo de tipo kmedias usando la información del csv original.

**Preprocesamiento**

Cabe destacar, que en este caso, hemos realizado unas modificaciones al set en python, con los scripts /scripts/cleaner.py y /scripts/scorer.py. Como resumen del funcionamiento de estos scripts, toman el dataset original "international_matches", eliminamos los amistosos para deshacernos de la correlación de cuidad-torneo-pais calculamos la media de puntos en portería, defensa, medio y ataque para cada país. Esta información la volcamos en el dataset "kmedias_input".

**Imputación de valores**

Sin embargo, tenemos valores faltantes dentro del dataset. Para ello, usaremos la imputación de valores faltantes aplicando distintas técnicas, como knnImpute, medianImpute y bagImpute. Nos quedaremos con el mejor de los 3.

```{r}
teams_data <- read_csv("datasets/kmedias_input.csv")

# Interpolar valores nulos del dataset

qatar = teams_data[nrow(teams_data), ]
bagMissing <- preProcess(teams_data, method = "medianImpute")
teams_data[nrow(teams_data), ] <- predict(bagMissing, qatar)
```

**Elección del mejor modelo**

```{r}

```

Con medianImpute hemos obtenido los mejores valores, ya que Qatar esta rankeada con valoraciones similares a equipos que sabemos que tienen el mismo nivel, como Ecuador o Ghana.

**Clustering**

Ahora que ya tenemos todos los valores, vamos a calcular los clusteres para agrupar el dataset.

```{r}

# Normaliza las columnas que quieres usar para agrupar los equipos
teams_data_normalized <- scale(teams_data[, colnames(teams_data)[-1]])

# Aplica el algoritmo de k-medias con k = 3 clústeres y 10 iteraciones
resultados <- kmeans(teams_data_normalized, 3, nstart = 10)
resultados[1]
```

Hemos obtenido 3 clusteres de equipos. Ahora vamos a visualizar los clústeres, en base al ranking fifa y a sus puntuaciones en las 4 categorías

**Visualización de los clústeres**

```{r}
clusters <- vector("list", length = length(unique(resultados$cluster)))

colormap <- colorRampPalette(c("red", "yellow", "green"))(length(unique(resultados$cluster)))

teams_data$color <- "#000000"

for (val in unique(resultados$cluster)) {
  cluster <- which(resultados$cluster == val)
  clusters[[val]] <- c(teams_data[cluster,])
  for (team in clusters[[val]]$team) {
    teams_data[teams_data$team == team, ]$color <- colormap[[val]]
  }
}

ggplot(teams_data, aes(x = fifa_rank, y = goalkeeper_score, color = color)) +
  geom_point() + geom_text_repel(aes(label = team)) + ggtitle("Goalkeeper Score")

ggplot(teams_data, aes(x = fifa_rank, y = mean_defense_score, color = color)) +
  geom_point() + geom_text_repel(aes(label = team)) + ggtitle("Mean Defense Score")

ggplot(teams_data, aes(x = fifa_rank, y = mean_offense_score, color = color)) +
  geom_point() + geom_text_repel(aes(label = team)) + ggtitle("Mean Offense Score")

ggplot(teams_data, aes(x = fifa_rank, y = mean_midfield_score, color = color)) +
  geom_point() + geom_text_repel(aes(label = team)) + ggtitle("Mean Midfield Score")
```

Los 3 clústeres tienen sentido ya que podemos encontrar relaciones entre los miembros de cada cluster.

-   Clúster 1: Selecciones menores como Ghana, Ecuador, Qatar y Korea se encuentran en el mismo grupo, ya que tienen puntuaciones similares.

-   Clúster 2: Selecciones medianas como México, Polonia, Uruguay y Croacia están agrupadas en un mismo clúster. Tiene sentido de nuevo, ya que estas selecciones suelen ser terceras de grupo o pasar a eliminatorias pocas veces, siendo eliminadas de manera temprana en los mundiales, pero son claramente mejores que las selecciones del cluster 1.

-   Clúster 3: las mejores selecciones. Aquí tenemos a Argentina, Francia, Brasil, Inglaterra... Las siempre favoritas.

Podemos ver que en los 4 casos planteados, (portería, defensa, mediocentro, ataque), tenemos los mismos clusteres con los mismos equipos. La distribución es muy parecida, aunque no siempre igual. Por ejemplo, España tiene los 4 valores parecidos, pero Brasil denota un mejor ataque que defensa. De nuevo, tiene sentido ya que esta selección es conocida por la gran cantidad de atacantes élite que ha mantenido.

## Conclusiones del proyecto

En este proyecto hemos desarrollado dos tipos de algoritmos. Un algoritmo de aprendizaje supervisado para la predicción del resultado de los partidos del mundial de Qatar 2022, y un algoritmo de aprendizaje no supervisado para la clusterización y clasificación de estos equipos participantes del mundial en base a 4 parámetros de portería, defensa, mediocentro y ataque.

Hemos realizado distintas tareas, junto con todas sus explicaciones:

1.  Análisis explotatorio de un dataset

2.  Análisis del balanceo de clases y cómo solucionarlo

3.  Análisis de la correlación de atributos y cómo solucionarlo

4.  Filtrado y curación de los datos

5.  Evaluación de los atributos con algoritmos de tipo RandomForest

6.  Codificación LabelEnconding para evaluar los atributos

7.  Entrenamiento de múltiples modelos (NaiveBayes, KNN, SVM)

8.  Evaluación y selección del mejor clasificador

9.  Imputación de valores faltantes en el dataset con distintos métodos (bagImpute, knnImpute, medianImpute)

10. Clustering con KMedias

11. Visualización del dataset, de atributos, de modelos, comparativas y clústeres

Hemos podido conocer más a fondo el mundo del científico e ingeniero de datos, los procesos y tareas de un proyecto de inteligencia artificial y big data, aprender más sobre R y su utilidad para este sector y obtener varias conclusiones interesantes al respecto. La más importante de ellas, es trabajar bien el dataset. Hemos pasado una gran parte del tiempo curando el dataset que hemos obtenido de Kaggle y aunque fue una gran inversión de tiempo, luego los algoritmos fueron mucho más sencillos de obtener. Como dijo Abraham Lincoln "Dame 6 horas para cortar un árbol y pasaré 4 afilando el hacha"
